{
    "collab_server" : "",
    "contents" : "library(\"snow\")\ndyn.load(\"~/Document/LRCUDA/src/libLRCUDA.so\")\n\nLRCUDA <- function(x, y, n.comb = 2, error.threshhold = 0 , fold = 10, device.id = 0, cl = NULL){\n    if(!is.matrix(x)){\n        stop(\"x should be matrix type !\")\n    }\n  \n    if(nrow(x) != length(y)){\n        stop(\"x'rows is different from y'length !\")\n    }\n\n    task.num <- choose(ncol(x), n.comb)\n    x <- cbind(rep(1,length(y)), x) \n    device.num <- length(device.id)\n    \n \n    if(is.null(cl)){\n        \n        cl <- makeCluster(length(device.id), type = \"SOCK\")\n        \n    }else{\n        if(length(cl) != length(device.id)){\n            stop(\"device count should be equal to cluster size! Please check you configures.\")\n        }\n    }\n    \n    ###待处理\n#    clusterEvalQ(cl,library(LRCUDA))\n   clusterEvalQ(cl,source(file=\"LRCUDA.R\") \n\n   print(vector(\"list\", device.num))\n\n   para <- vector(\"list\", device.num)\n    task.piece <- floor(task.num / device.num)\t\n\n    for(i in 1:device.num){\n        para[[i]] <- list(x = x, y = y, n.comb = n.comb, error.threshhold = error.threshhold, fold = fold, device.id = device.id[i], start = (i-1)*task.piece + 1, stop = i*task.piece)\n    }\n    if(para[[device.num]]$stop < task.num){\n            para[[device.num]]$stop = task.num\n    }\n               \n    result <- clusterApply(cl, para, LRMultipleGPU)\n    return(combineResult(result))\n}\n\n\nX=matrix(1:12,ncol=3,nrow=4)\nY=c(1,3,4,5)\nLRCUDA(X,Y)\n\n\n\n\n",
    "created" : 1504841681529.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1493261114",
    "id" : "C0F1E69A",
    "lastKnownWriteTime" : 1504841731,
    "last_content_update" : 1504841731043,
    "path" : "~/Documents/LRCUDA/R/LRCUDA.R",
    "project_path" : "R/LRCUDA.R",
    "properties" : {
    },
    "relative_order" : 7,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}